{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st  # to render the user interface.\n",
    "from langchain_community.llms import Ollama  # to use Ollama llms in langchain\n",
    "from langchain_core.prompts import ChatPromptTemplate  # crafts prompts for our llm\n",
    "from langchain_community.chat_message_histories import\\\n",
    "    StreamlitChatMessageHistory  # stores message history\n",
    "from langchain_core.tools import tool  # tools for our llm\n",
    "# to describe tools as a string\n",
    "from langchain.tools.render import render_text_description\n",
    "# ensure JSON input for tools\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from operator import itemgetter  # to retrieve specific items in our chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ollama(model='mistral:instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(first: int, second: int) -> int:\n",
    "    \"Add two integers.\"\n",
    "    return first + second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add\n",
      "Add two integers.\n",
      "{'first': {'title': 'First', 'type': 'integer'}, 'second': {'title': 'Second', 'type': 'integer'}}\n"
     ]
    }
   ],
   "source": [
    "print(add.name)\n",
    "print(add.description)\n",
    "print(add.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.invoke({'first': 3, 'second': 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(first: int, second: int) -> int:\n",
    "    \"\"\"Multiply two integers together.\"\"\"\n",
    "    return first * second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def converse(input: str) -> str:\n",
    "    \"Provide a natural language response using the user input.\"\n",
    "    return model.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add(first: int, second: int) -> int - Add two integers.\n",
      "multiply(first: int, second: int) -> int - Multiply two integers together.\n",
      "converse(input: str) -> str - Provide a natural language response using the user input.\n"
     ]
    }
   ],
   "source": [
    "tools = [add, multiply, converse]\n",
    "rendered_tools = render_text_description(tools)\n",
    "print(rendered_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"You are an assistant that has access to the following set of tools.\n",
    "Here are the names and descriptions for each tool:\n",
    "\n",
    "{rendered_tools}\n",
    "Given the user input, return the name and input of the tool to use.\n",
    "Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
    "The value associated with the 'arguments' key should be a dictionary of parameters.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system_prompt), (\"user\", \"{input}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'multiply', 'arguments': {'first': 3, 'second': 23}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'What is 3 times 23'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'converse', 'arguments': {'input': 'How are you today?'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({'input': 'How are you today?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function which returns the chosen tool\n",
    "# to be run as part of the chain.\n",
    "def tool_chain(model_output):\n",
    "    tool_map = {tool.name: tool for tool in tools}\n",
    "    chosen_tool = tool_map[model_output[\"name\"]]\n",
    "    return itemgetter(\"arguments\") | chosen_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | JsonOutputParser() | tool_chain\n",
    "chain.invoke({'input': 'What is 3 times 23'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlist chat history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-02 20:29:46.776 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2024-07-02 20:29:46.795 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/avatsaev/miniconda3/envs/ai/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "# Set up message history.\n",
    "msgs = StreamlitChatMessageHistory(key=\"langchain_messages\")\n",
    "if len(msgs.messages) == 0:\n",
    "    msgs.add_ai_message(\n",
    "        \"I can add, multiply, or just chat! How can I help you?\")\n",
    "\n",
    "st.title(\"Chatbot with tools\")\n",
    "\n",
    "# Render the chat history.\n",
    "for msg in msgs.messages:\n",
    "    st.chat_message(msg.type).write(msg.content)\n",
    "\n",
    "\n",
    "# React to user input\n",
    "if input := st.chat_input(\"What is up?\"):\n",
    "    # Display user input and save to message history.\n",
    "    st.chat_message(\"user\").write(input)\n",
    "    msgs.add_user_message(input)\n",
    "    # Invoke chain to get reponse.\n",
    "    response = chain.invoke({'input': input})\n",
    "    # Display AI assistant response and save to message history.\n",
    "    st.chat_message(\"assistant\").write(str(response))\n",
    "    msgs.add_ai_message(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
